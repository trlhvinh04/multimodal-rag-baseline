{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from io import StringIO  # Để làm việc với chuỗi như một tệp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tables/CA_WARN_REPORT\"\n",
    "\n",
    "tables = [file for file in os.listdir(path=path) if file.endswith('.csv')]\n",
    "tables = sorted(tables, key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "tables = [f\"{path}/{table}\" for table in tables]\n",
    "\n",
    "dfs = [pd.read_csv(file) for file in tables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### table_fragment_1\n",
      "Headers: Notice Date,Effective,Received,Company,City,No. Of,Layoff/Closure\n",
      "06/22/2015=03/25/2016=07/01/2015=Maxim Integrated Product=San Jose=150=Closure Permanent\n",
      "06/30/2015=08/29/2015=07/01/2015=McGraw-Hill Education=Monterey=137=Layoff Unknown at this time\n",
      "07/14/2015=09/18/2015=07/20/2015=Actavis, Inc.=Corona=45=Layoff Permanent\n",
      "07/17/2015=07/13/2015=07/21/2015=American Management Services LLC=Monterey=56=Closure Permanent\n",
      "07/08/2015=09/06/2015=07/08/2015=Microsoft Corporation=San Diego=129=Layoff Permanent\n",
      "06/30/2015=08/31/2015=07/13/2015=First Transit=Rancho=71=Layoff Permanent\n",
      "07/10/2015=07/14/2015=07/13/2015=11 Main LLC=Chico=44=Layoff Permanent\n",
      "\n",
      "\n",
      "Note that:\n",
      "- Number of columns is: 7 \n",
      "- Data type of each column is: ['object', 'object', 'object', 'object', 'object', 'numeric', 'object']\n",
      "\n",
      "### table_fragment_2\n",
      "Headers: 03/08/2016,11/11/2016,03/10/2016,Corning Incorporated,Union City,193,Closure Permanent\n",
      "03/01/2016=05/06/2016=03/11/2016=Pacific Bell Telephone Company=Tustin=3=Layoff Permanent\n",
      "03/10/2016=05/13/2016=03/11/2016=Carbine, LLC=Aliso Viejo=18=Layoff Unknown at this time\n",
      "03/18/2016=05/20/2016=03/23/2016=Boeing Company=El Segundo=26=Layoff Unknown at this time\n",
      "03/21/2016=05/27/2016=03/23/2016=Rockwell Collins, Inc.=Poway=2=Layoff Unknown at this time\n",
      "03/18/2016=05/17/2016=03/21/2016=Williams-Sonoma, Inc.=Richmond=1=Layoff Permanent\n",
      "03/10/2016=03/11/2016=03/14/2016=NC Interactive, LLC=Aliso Viejo=11=Layoff Permanent\n",
      "03/18/2016=05/17/2016=03/21/2016=Williams-Sonoma, Inc.=Brisbane=3=Layoff Permanent\n",
      "\n",
      "\n",
      "Note that:\n",
      "- Number of columns is: 7 \n",
      "- Data type of each column is: ['object', 'object', 'object', 'object', 'object', 'numeric', 'object']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from check_using_api import prepare_df_for_prompt\n",
    "\n",
    "print(prepare_df_for_prompt(dfs[0], dfs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column_equal(df1, df2):\n",
    "    if df1.shape[1] != df2.shape[1]:\n",
    "        print(\"Hai df không có cùng số cột\")\n",
    "        return False\n",
    "    print(\"Hai df có cùng số cột\")\n",
    "    \n",
    "    if df1.columns.equals(df2.columns):\n",
    "        print(\"Hai df có cùng tên cột\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Hai df không có cùng tên cột\")\n",
    "        return False\n",
    "    \n",
    "def check_data_type_equal(df1, df2):\n",
    "    pass\n",
    "    \n",
    "def solve_non_header_table(df, headers):\n",
    "    # Convert unnamed columns to NaN in first row\n",
    "    first_row_values = []\n",
    "    for col in df.columns:\n",
    "        if str(col).startswith('Unnamed'):\n",
    "            first_row_values.append(np.nan)\n",
    "        else:\n",
    "            first_row_values.append(col)\n",
    "            \n",
    "    temp_firstrow = pd.DataFrame([first_row_values], columns=headers)\n",
    "    df.columns = headers\n",
    "\n",
    "    # insert temp_data in to the first row \n",
    "    df = pd.concat([pd.DataFrame(temp_firstrow, columns=headers), df], ignore_index=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def concat_df(df1, df2):\n",
    "    concated_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    return concated_df\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Hàm trợ giúp để thực hiện logic sniffing, tránh lặp code\n",
    "def _perform_csv_sniffing(csv_sample_string: str) -> bool:\n",
    "    \"\"\"\n",
    "    Thực hiện việc \"đánh hơi\" trên một chuỗi CSV mẫu.\n",
    "    Trả về True nếu có vẻ có header, False nếu ngược lại hoặc có lỗi.\n",
    "    \"\"\"\n",
    "    if not csv_sample_string.strip():\n",
    "        # Mẫu rỗng hoặc chỉ chứa khoảng trắng thì không có header\n",
    "        return False\n",
    "\n",
    "    sniffer = csv.Sniffer()\n",
    "    try:\n",
    "        # sniffer.has_header() trả về True nếu nó tin rằng có header.\n",
    "        # Hàm này hoạt động dựa trên việc so sánh dòng đầu tiên với các dòng tiếp theo.\n",
    "        # Nó có thể không hoàn hảo cho mọi trường hợp phức tạp hoặc mơ hồ.\n",
    "        return sniffer.has_header(csv_sample_string)\n",
    "    except csv.Error:\n",
    "        # Nếu Sniffer lỗi (không xác định được dialect, cấu trúc quá mơ hồ),\n",
    "        # coi như không thể xác nhận sự tồn tại của header chuẩn.\n",
    "        # Điều này có thể xảy ra nếu mẫu quá ngắn, hoặc có ký tự/cấu trúc bất thường.\n",
    "        return False\n",
    "\n",
    "def has_header(data_source: any) -> bool:\n",
    "    \"\"\"\n",
    "    Phát hiện xem một tệp CSV hoặc một pandas DataFrame có khả năng có header hay không.\n",
    "\n",
    "    Đối với cả hai loại đầu vào, hàm sẽ sử dụng csv.Sniffer trên một mẫu dữ liệu.\n",
    "    Đối với DataFrame, một mẫu (bao gồm cả tên cột hiện tại của DataFrame) sẽ được chuyển đổi\n",
    "    thành chuỗi CSV và sau đó được \"đánh hơi\".\n",
    "\n",
    "    Args:\n",
    "        data_source (str or pd.DataFrame): Đường dẫn đến tệp CSV\n",
    "                                           hoặc một đối tượng pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        bool: True nếu nguồn dữ liệu có khả năng CÓ header theo Sniffer.\n",
    "              False trong các trường hợp khác (không có header, rỗng, lỗi, kiểu không hỗ trợ).\n",
    "    \"\"\"\n",
    "    MAX_SAMPLE_ROWS_FOR_DF = 15  # Số dòng dữ liệu từ DataFrame để lấy mẫu (không tính header DF)\n",
    "                                 # Tổng số dòng trong chuỗi CSV sẽ là MAX_SAMPLE_ROWS_FOR_DF + 1 (cho header DF)\n",
    "    MAX_FILE_LINES_FOR_SAMPLE = 15 # Số dòng đọc từ tệp để làm mẫu\n",
    "\n",
    "    if isinstance(data_source, pd.DataFrame):\n",
    "        df = data_source\n",
    "        if df.empty:\n",
    "            return False # DataFrame rỗng thì không có header\n",
    "\n",
    "        columns = df.columns.tolist()\n",
    "\n",
    "        # Heuristic 1: Kiểm tra xem tên cột có phải là một dãy số nguyên tăng dần không\n",
    "        # (ví dụ: 0, 1, 2, ...), thường là dấu hiệu pandas tự tạo header.\n",
    "        is_sequential_integers = True\n",
    "        if not columns: # Nếu DataFrame không có cột nào\n",
    "             is_sequential_integers = False\n",
    "        else:\n",
    "            for i, col_name_obj in enumerate(columns):\n",
    "                # Tên cột có thể là số nguyên, hoặc chuỗi chứa số. Chuyển sang chuỗi để đảm bảo.\n",
    "                col_name_str = str(col_name_obj)\n",
    "                try:\n",
    "                    col_val = int(col_name_str)\n",
    "                    if col_val != i:\n",
    "                        is_sequential_integers = False\n",
    "                        break\n",
    "                except ValueError: # Nếu tên cột không thể chuyển thành số nguyên\n",
    "                    is_sequential_integers = False\n",
    "                    break\n",
    "        \n",
    "        if is_sequential_integers: # True nếu tất cả tên cột là dãy 0, 1, 2...\n",
    "            # print(\"Debug: DataFrame columns are sequential integers, assuming no meaningful header.\")\n",
    "            return False\n",
    "\n",
    "        # Heuristic 2: Kiểm tra nếu có tên cột nào bắt đầu bằng 'Unnamed:'\n",
    "        # Đây cũng là dấu hiệu thường thấy khi pandas đọc CSV không có header\n",
    "        # hoặc header có các ô trống.\n",
    "        for col in columns:\n",
    "            if str(col).startswith('Unnamed'):\n",
    "                # print(\"Debug: DataFrame has 'Unnamed' column, assuming no meaningful header or problematic header.\")\n",
    "                return False\n",
    "        \n",
    "        # Lấy một phần DataFrame để chuyển thành chuỗi CSV\n",
    "        # df.head(n) sẽ lấy n dòng đầu tiên của dữ liệu.\n",
    "        # Khi to_csv(header=True), nó sẽ thêm 1 dòng header nữa từ df.columns.\n",
    "        sample_df = df.head(MAX_SAMPLE_ROWS_FOR_DF)\n",
    "        \n",
    "        csv_string_buffer = StringIO()\n",
    "        # Chuyển DataFrame mẫu thành chuỗi CSV, bao gồm header của DataFrame\n",
    "        # và không bao gồm index của DataFrame.\n",
    "        sample_df.to_csv(csv_string_buffer, header=True, index=False)\n",
    "        csv_sample_from_df = csv_string_buffer.getvalue()\n",
    "        \n",
    "        # print(f\"Debug: CSV sample from DataFrame for sniffing:\\n{csv_sample_from_df[:200]}\") # In ra vài trăm ký tự đầu\n",
    "        return _perform_csv_sniffing(csv_sample_from_df)\n",
    "\n",
    "    elif isinstance(data_source, str):  # Đầu vào là đường dẫn tệp\n",
    "        file_path = data_source\n",
    "        try:\n",
    "            # Sử dụng encoding='utf-8-sig' để xử lý trường hợp file có BOM (Byte Order Mark)\n",
    "            # BOM là một ký tự đặc biệt ở đầu file UTF-8 có thể gây nhiễu Sniffer nếu không được bỏ qua.\n",
    "            # newline='' được khuyến nghị khi làm việc với file CSV.\n",
    "            with open(file_path, 'r', newline='', encoding='utf-8-sig') as csv_file:\n",
    "                sample_lines_list = []\n",
    "                for i, line_content in enumerate(csv_file):\n",
    "                    # Đọc tối đa MAX_FILE_LINES_FOR_SAMPLE dòng\n",
    "                    if i >= MAX_FILE_LINES_FOR_SAMPLE:\n",
    "                        break\n",
    "                    sample_lines_list.append(line_content) # line_content đã bao gồm ký tự xuống dòng\n",
    "                \n",
    "                if not sample_lines_list: # File rỗng hoặc không đọc được dòng nào\n",
    "                    # print(f\"Debug: File '{file_path}' is empty or no lines were read for sample.\")\n",
    "                    return False\n",
    "\n",
    "                csv_sample_from_file = \"\".join(sample_lines_list)\n",
    "                # print(f\"Debug: CSV sample from file '{file_path}' for sniffing:\\n{csv_sample_from_file[:200]}\")\n",
    "                return _perform_csv_sniffing(csv_sample_from_file)\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            # print(f\"Error: File not found at '{file_path}'.\")\n",
    "            return False \n",
    "        except Exception as e: # Bắt các lỗi khác liên quan đến tệp (ví dụ: lỗi encoding nếu file không phải utf-8/utf-8-sig)\n",
    "            # print(f\"An unexpected file error occurred: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        # print(f\"Error: Unsupported data_source type '{type(data_source)}'.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table 1 of 4\n",
      "Input tokens: 139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tokens: 6\n",
      "Processing table 2 of 4\n",
      "Input tokens: 136\n",
      "Output tokens: 6\n",
      "Processing table 3 of 4\n",
      "Hai df không có cùng số cột\n",
      "Phát hiện table mới\n",
      "Processing table 4 of 4\n",
      "Input tokens: 85\n",
      "Output tokens: 6\n"
     ]
    }
   ],
   "source": [
    "### Giả sử rằng tất cả các table đều xuất hiện một cách tuần tự\n",
    "### Giả sử table đầu tiên là nó phải ở dạng chuẩn (có headers)\n",
    "from check_using_api import prepare_df_for_prompt, generate\n",
    "\n",
    "first_table = dfs[0]\n",
    "first_header = first_table.columns.tolist()\n",
    "processed_tables = []\n",
    "\n",
    "for idx, df in enumerate(dfs[1:]):\n",
    "    print(f\"Processing table {idx + 1} of {len(dfs) - 1}\")\n",
    "    if has_header(df):\n",
    "        # check chung header\n",
    "        if check_column_equal(first_table, df):\n",
    "            # nếu bằng header thì concat\n",
    "            first_table = concat_df(first_table, df)\n",
    "        else:\n",
    "            # nếu không thì là một table hoàn toàn mới\n",
    "            print(\"Phát hiện table mới\")\n",
    "            processed_tables.append(first_table)\n",
    "            first_table = df\n",
    "            first_header = first_table.columns.tolist()\n",
    "    else:\n",
    "        # nếu không có header thì gọi api check thử (hoặc code logic sau)\n",
    "        prompt = prepare_df_for_prompt(first_table, df)\n",
    "        response = generate(prompt)\n",
    "        if response[\"is_continuation\"]:\n",
    "            # nếu đúng thì concat\n",
    "            solved_df = solve_non_header_table(df, first_header)\n",
    "            first_table = concat_df(first_table, solved_df)\n",
    "        else:\n",
    "            # nếu sai thì có thể đây là một table mới nhưng không có header\n",
    "            # cần xử lý riêng table này\n",
    "            processed_tables.append(first_table)\n",
    "            first_table = df  # Bắt đầu một table mới\n",
    "            first_header = response[\"second_table_header\"]\n",
    "            print(f\"Warning: Table {idx + 1} has no header and cannot be joined with previous table\")\n",
    "\n",
    "# Đảm bảo table cuối cùng được thêm vào processed_tables\n",
    "processed_tables.append(first_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(processed_tables)):\n",
    "    with open(f\"test_table_{i}.txt\", \"w\") as f:\n",
    "        f.write(processed_tables[i].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
